# Simple-Text-Tokenization-and-Lemmatization-Tool-Rule-Based-

# ðŸ§¹ Text Cleaner Tool (Tokenization & Stemming)

A simple Python-based command-line tool that takes a sentence, tokenizes it, applies basic rule-based stemming, displays the cleaned result, and saves it to a log file.

## ðŸ“¦ Project Structure
text_cleaner_tool/
â”œâ”€â”€ main.py # Main driver script
â”œâ”€â”€ README.md # Project description and instructions
â”œâ”€â”€ modules/ # Contains all processing modules
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ input_module.py # Takes user input
â”‚ â”œâ”€â”€ tokenizer.py # Splits sentence into tokens
â”‚ â”œâ”€â”€ stemmer.py # Applies rule-based stemming
â”‚ â”œâ”€â”€ cleaner_viewer.py # Displays original vs cleaned tokens
â”‚ â””â”€â”€ log_exporter.py # Saves cleaned tokens to a log file

---

## ðŸš€ How It Works

1. The program asks you to enter a sentence.
2. It splits the sentence into individual words (tokens).
3. Applies simple rule-based stemming to clean the words.
4. Displays both original and cleaned words side by side.
5. Saves the cleaned words to logs/cleaned_output.txt.

---

## ðŸ”§ Requirements

- Python 3.6 or higher
- No external libraries required (uses only built-in modules)

---

## Run the main script

run main.py


